import os
from google.cloud import vision, translate

# âœ… ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "brailliant-ocr-f77fc2866f5b.json"

# âœ… ì–¸ì–´ ì´ë¦„ â†’ Google ë²ˆì—­ ì½”ë“œ ë§¤í•‘
LANGUAGE_CODE_MAP = {
    "english": "en",
    "korean": "ko",
    "spanish": "es",
    "chinese": "zh"
}

def perform_ocr_and_translate(image_path, target_language=None):
    # âœ… OCR í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = vision.ImageAnnotatorClient()

    with open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    texts = response.text_annotations
    print("ğŸ” OCR ê²°ê³¼:", texts)

    if not texts:
        return "", "No text found in image."

    detected_text = texts[0].description.strip()

    # âœ… ì–¸ì–´ ë¯¸ì„ íƒ ì‹œ ì›ë¬¸ ë°˜í™˜
    if not target_language:
        return detected_text, "No language selected. Using English as default."

    # âœ… ì–¸ì–´ ì½”ë“œ ë³€í™˜ (ìœ íš¨ì„± ê²€ì‚¬ í¬í•¨)
    lang_code = LANGUAGE_CODE_MAP.get(target_language.lower())
    if not lang_code:
        return detected_text, f"Invalid language selected: {target_language}. Using English as default."
    
    # âœ… ë²ˆì—­ ìš”ì²­
    translate_client = translate.TranslationServiceClient()
    parent = "projects/brailliant-ocr/locations/global"  # ì‹¤ì œ í”„ë¡œì íŠ¸ ID ì‚¬ìš©

    response = translate_client.translate_text(
        contents=[detected_text],
        target_language_code=lang_code,
        parent=parent
    )

    translated_text = response.translations[0].translated_text
    return translated_text, None
